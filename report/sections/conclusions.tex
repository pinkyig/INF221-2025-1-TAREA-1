En este trabajo se llevó a cabo una evaluación experimental de cinco algoritmos clásicos —tres de ordenamiento (SelectionSort, MergeSort y QuickSort, junto con la implementación de \texttt{std::sort}) y dos de multiplicación de matrices (Naive y Strassen)— sobre diversos tipos de entrada y tamaños crecientes. El objetivo planteado en la introducción—cuantificar la brecha entre complejidad teórica y rendimiento real bajo condiciones controladas—se ha alcanzado satisfactoriamente mediante la obtención de mediciones reproducibles y un análisis comparativo detallado.

Para los algoritmos de ordenamiento, los resultados confirman la penalización dramática del enfoque cuadrático de SelectionSort frente a las curvas O(\(n\log n\)) de MergeSort, QuickSort y \texttt{std::sort}. En todos los escenarios (aleatorio, ascendente y descendente) SelectionSort se vuelve inviable a partir de \(n\approx10^5\), mientras que MergeSort y QuickSort mantienen tiempos moderados incluso para \(n=10^7\), destacando la robustez de \texttt{std::sort} como la opción más eficiente en promedio

Respecto a la multiplicación de matrices, el método Naive exhibe el crecimiento cúbico esperado, superando los 6 400 ms para \(n=1024\), mientras que Strassen logra ventajas marginales alrededor de \(n=256\), pero ve reducida su eficacia práctica en grandes dimensiones debido al overhead recursivo y al coste de memoria adicional. Al explorar matrices diagonales y dispersas, se confirmó que la escasez de elementos no nulos acelera ambos algoritmos en rangos pequeños (\(n\le64\)), aunque a partir de \(n\ge256\) las mejoras teóricas quedan amortiguadas por el coste de acceso y verificación de ubicaciones nulas.

En conjunto, estos hallazgos ponen de manifiesto que la elección de algoritmo debe basarse no solo en su orden de complejidad asintótica, sino también en características prácticas del hardware (cache, gestión de memoria) y del patrón de datos. Para aplicaciones con matrices de gran tamaño, una implementación híbrida o bloqueada que combine lo mejor de Naive y Strassen, o el uso de bibliotecas optimizadas, podría ofrecer ventajas adicionales.

Finalmente, los resultados alcanzados responden al planteamiento inicial al demostrar que las discrepancias entre teoría y práctica son sustanciales: la sobrecarga de gestión de memoria y recursividad puede anular las ganancias teóricas en escenarios reales, y solo un análisis experimental riguroso permite identificar la opción óptima en cada contexto. Como trabajo futuro, se sugiere analizar variantes paralelas y basadas en BLAS para extender la validez de estas conclusiones a entornos de alto rendimiento.
